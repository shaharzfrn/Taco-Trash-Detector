{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course CS236781: Deep Learning Final Mini Project\n",
    "\n",
    "## The Guidelines as given:\n",
    ">\n",
    ">\n",
    ">In this part you'll implement a small comparative-analysis project, heavily based on the materials from the tutorials and homework.\n",
    ">- You should implement the code which displays your results in this notebook, and add any additional code files for your implementation in the `project/` directory. You can import these files here, as we do for the homeworks.\n",
    ">- Running this notebook should not perform any training - load your results from some output files and display them here. The notebook must be runnable from start to end without errors.\n",
    ">- You must include a detailed write-up (in the notebook) of what you implemented and how. \n",
    ">- Explain the structure of your code and how to run it to reproduce your results.\n",
    ">- Explicitly state any external code you used, including built-in pytorch models and code from the course tutorials/homework.\n",
    ">- Analyze your numerical results, explaining **why** you got these results (not just specifying the results).\n",
    ">- Where relevant, place all results in a table or display them using a graph.\n",
    ">\n",
    ">\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Projects Goals\n",
    "\n",
    ">\n",
    ">\n",
    ">* You need to perform Object Detection task, over 7 of the dataset.\n",
    ">* The annotation for object detection can be downloaded from here: https://github.com/wimlds-trojmiasto/detect-waste/tree/main/annotations.\n",
    ">* The data and annotation format is like the COCOAPI: https://github.com/cocodataset/cocoapi (you can find a notebook of how to perform evalutation using it here: https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb)\n",
    ">(you need to install it..)\n",
    ">* if you need a beginner guild for OD in COCOAPI, you can read and watch this link: https://www.neuralception.com/cocodatasetapi/ \n",
    ">\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Implementation\n",
    "\n",
    "This is the Implementation my partener to this project [dorin133](https://github.com/dorin133) and I decided go with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clone yolov7 and install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/WongKinYiu/yolov7\n",
    "!pip install -r ./yolov7/requirements.txt\n",
    "\n",
    "%cd yolov7\n",
    "\n",
    "# download COCO starting checkpoint\n",
    "!wget -O yolov7_training.pt https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6e_training.pt\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "!pip install pycocotools\n",
    "!pip install split-folders\n",
    "!pip install lion-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotation import json2texts\n",
    "from consts import taco_annotations_path, taco_dataset_save_path\n",
    "\n",
    "folders = ['train', 'test']\n",
    "\n",
    "for f in folders:\n",
    "    json2texts(f'{taco_annotations_path}/annotations_{f}.json', f'{taco_dataset_save_path}/{f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from consts import taco_annotations_path, taco_dataset_save_path\n",
    "\n",
    "pwd = '.'\n",
    "\n",
    "%cd {pwd}/yolov7\n",
    "!python train.py --img 640 --epochs 22 --data ../{taco_dataset_save_path}/taco.yaml --cfg ./cfg/training/yolov7.yaml --weights yolov7_training.pt --batch-size 8 --adam\n",
    "\n",
    "!mkdir -p weights\n",
    "# copy the last trained best weights to weights folder\n",
    "\n",
    "# example: \n",
    "# !cp runs/train/exp28/weights/best.pt weights/\n",
    "# will copy train 28 to weights\n",
    "!cp runs/train/exp1/weights/best.pt weights/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detect & Display the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python detect.py --weights weights/best.pt --conf 0.4 --source ../{taco_dataset_save_path}/test-test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('./runs/detect/exp43/papper.jpeg')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
