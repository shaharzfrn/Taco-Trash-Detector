{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dul_hEvDDR3g"
   },
   "source": [
    "# Taco Dataset Setup\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1.   Clone wimlds-trojmiasto/detect-waste repository and install requirements\n",
    "2.   Create 2 forlders for the dataset images in *Google Drive*\n",
    "3.   Download all the train & test images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCnt3-yZEzrG"
   },
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_58OkXVCREG"
   },
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1srl5rh2DupJ"
   },
   "source": [
    "# 2. Mount Google Drive and create 2 forlders for the dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OhCQlOQCD4bt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%mkdir -p taco-dataset/train\n",
    "%mkdir -p taco-dataset/val\n",
    "\n",
    "taco_train_dataset = 'taco-dataset/train'\n",
    "taco_test_dataset = 'taco-dataset/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zshbMlUvEyqK"
   },
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yLOYqjrCdko"
   },
   "source": [
    "# 3. Download the dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CsdTfJGEEUpd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tqdm # can be remvoe\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LeRHlADa8h9p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def annotation2text(image_info, dst_path, dataset):\n",
    "\n",
    "    buffer = ''\n",
    "    boxes = np.zeros((0, 5))\n",
    "\n",
    "    #file_name = f\"{image_info['id']}.txt\"\n",
    "    file_name = image_info['file_name'].replace('/', '_').split('.')[0] + '.txt'\n",
    "    save_path = f\"{dst_path}/{file_name}\"\n",
    "\n",
    "    width, height = image_info['width'], image_info['height']\n",
    "\n",
    "    annotation_ids = dataset.getAnnIds(image_info['id'])\n",
    "    annotations = dataset.loadAnns(annotation_ids) if len(annotation_ids) != 0 else []\n",
    "\n",
    "    for annotation in annotations:\n",
    "        box = annotation['bbox']\n",
    "\n",
    "        if box[2] < 1 or box[3] < 1:\n",
    "            continue\n",
    "\n",
    "        box[0] = ((box[0] + box[2] / 2) / width)\n",
    "        box[1] = ((box[1] + box[3] / 2) / height)\n",
    "        box[2] = (box[2] / width)\n",
    "        box[3] = (box[3] / height)\n",
    "\n",
    "        label = (annotation[\"category_id\"] - 1)\n",
    "        buffer = buffer + str(label)\n",
    "        for i in box:\n",
    "            buffer += ' ' + str(i)\n",
    "\n",
    "        buffer += '\\n'\n",
    "    \n",
    "    with open(save_path, 'w') as fp:\n",
    "        fp.writelines(buffer)\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def json2texts(annotation_file, dst):\n",
    "    '''\n",
    "    annotation_file: the annotation file\n",
    "    src: Path to source images\n",
    "    dst: Path to place the data\n",
    "    '''\n",
    "    \n",
    "    # if the dst folder exists, delete it\n",
    "    if os.path.isdir(dst):\n",
    "        shutil.rmtree(dst)\n",
    "\n",
    "    # create the dst dir\n",
    "    os.makedirs(dst)\n",
    "\n",
    "\n",
    "    labels_save_path = f'{dst}/labels/'\n",
    "    images_save_path = f'{dst}/images/'\n",
    "\n",
    "    # create Images & Lables folder in dst folder\n",
    "    os.mkdir(labels_save_path)\n",
    "    os.mkdir(images_save_path)\n",
    "\n",
    "\n",
    "    dataset = COCO(annotation_file=annotation_file)\n",
    "    image_ids = dataset.getImgIds()\n",
    "\n",
    "    for image_id in tqdm.tqdm(image_ids, desc='change .json file to .txt file'):\n",
    "\n",
    "        image_info = dataset.loadImgs(image_id)[0]\n",
    "        try:\n",
    "            file_name = image_info['file_name'].replace('/', '_') #f\"{image_info['id']}.{image_info['flickr_640_url'].split('.')[-1]}\"\n",
    "            save_path = f\"{images_save_path}/{file_name}\"\n",
    "            \n",
    "            raw_image = Image.open(requests.get(image_info['flickr_url'], stream=True).raw)\n",
    "            with open(save_path, 'wb') as file:\n",
    "                raw_image.save(file)\n",
    "\n",
    "            annotation2text(image_info, labels_save_path, dataset)\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(f\"Image {image_info['id']} FAILED!!!!! {image_info}\", e)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # insted of copy image, download it\n",
    "        \n",
    "        #shutil.copy(f\"{src}/{image_info['id']}.jpg\", f\"{images_save_path}/{image_info['id']}.jpg\")\n",
    "\n",
    "\n",
    "    return dst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "SSpap94lupxP",
    "outputId": "44877a23-6758-4b61-b2a2-8807316b1b6f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "change .json file to .txt file: 100%|███████| 3647/3647 [08:17<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "change .json file to .txt file: 100%|█████████| 915/915 [02:04<00:00,  7.37it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folders = ['train', 'test']\n",
    "for f in folders:\n",
    "    json2texts(f'taco-dataset/annotations/annotations_{f}.json', f'taco-dataset/{f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
